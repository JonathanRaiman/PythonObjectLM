{
 "metadata": {
  "name": "",
  "signature": "sha256:79aa124788503f43be2c0540a076a881d168d199e58e7358b6014f1960df611d"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "% load_ext autoreload\n",
      "% autoreload 2\n",
      "% matplotlib inline\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import gzip, pickle, os\n",
      "import sparkfun"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The autoreload extension is already loaded. To reload it, use:\n",
        "  %reload_ext autoreload\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Scraping Sparkfun for ObjectLM\n",
      "\n",
      "Here we scrape pages from [Sparkfun](https://www.sparkfun.com) to get metadata and text. First let's make sure we only hit their service once for each html page with a dictionary holding page html trees.\n",
      "\n",
      "Parse each top page for categories, and from each category get the top listed item's categories, description, and price."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "products = sparkfun.scrape_pages()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "seed 0 / 31 : 48 products\n",
        "seed 1 / 31 : 10 products"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "seed 2 / 31 : 8 products"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "seed 3 / 31 : 28 products"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "seed 4 / 31 : 20 products"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "seed 5 / 31 : 48 products"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "seed 6 / 31 : 48 products"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "seed 7 / 31 : 13 products"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "seed 8 / 31 : 48 products"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "seed 9 / 31 : 30 products"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "seed 10 / 31 : 39 products"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "seed 11 / 31 : 48 products"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "seed 12 / 31 : 48 products"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "seed 13 / 31 : 21 products"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "seed 14 / 31 : 48 products"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "seed 15 / 31 : 48 products"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "seed 16 / 31 : 21 products"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "seed 17 / 31 : 48 products"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "seed 18 / 31 : 48 products"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 87
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Save the parsed data to a file:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "os.makedirs(\"saves/sparkfun/\", exist_ok=True)\n",
      "with gzip.open(\"saves/sparkfun/products.pkl\", \"wb\") as f:\n",
      "    pickle.dump([(product.sku, product.name, product.description, product.categories, product.price) for product in products.values()], f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 108
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with gzip.open(\"saves/sparkfun/products.pkl\", \"rb\") as f:\n",
      "    stuff = pickle.load(f)\n",
      "\n",
      "products = {}\n",
      "for product_args in stuff:\n",
      "    product = sparkfun.Product(*product_args)\n",
      "    products[product.sku] = product"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Construct a predictive model for pricing and categories as a stacked LSTM system with an MLP on the last hidden state outputting the price as a float:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "index2category, category2index, index2word, word2index = sparkfun.create_indices(products)\n",
      "data, codelens, sequence_lengths, prices = sparkfun.create_labeled_dataset(products, index2category, category2index, index2word, word2index, 10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Ensure low sparsity of these batches:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sparkfun.sparsity(data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 29,
       "text": [
        "0.8436045710526666"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Construct the model:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "product_model = sparkfun.ProductModel(100, len(index2word), 4, 100, 100, 3, len(index2category),\n",
      "                             verbose=True,\n",
      "                             rho=0.95,\n",
      "                             memory_sparsity=0.3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "created prediction & error functions\n",
        "took the gradient"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "created the gradient descent function"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "epochs = 10\n",
      "for epoch in range(epochs):\n",
      "    training_loop()\n",
      "    if epoch % 2 == 0:\n",
      "        print(\"epoch %d : error %.3f\" % (epoch, average_error()))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 490,
       "text": [
        "array(114025.1400152439)"
       ]
      }
     ],
     "prompt_number": 490
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time \n",
      "training_loop()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 44.2 s, sys: 6.36 s, total: 50.6 s\n",
        "Wall time: 47.7 s\n"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "product_model.reset_weights()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 499
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def average_error():\n",
      "    error = 0.\n",
      "    size = 0\n",
      "    for data_batch, sequence_lengths_batch, codelens_batch, prices_batch in zip(data, sequence_lengths, codelens, prices):\n",
      "        error += product_model.error_fun(data_batch,\n",
      "                                      codelens_batch,\n",
      "                                 sequence_lengths_batch,\n",
      "                                 prices_batch) * len(data_batch)\n",
      "        size += len(data_batch)\n",
      "    return error / size\n",
      "\n",
      "def training_loop():\n",
      "    for data_batch, sequence_lengths_batch, codelens_batch, prices_batch in zip(data, sequence_lengths, codelens, prices):\n",
      "        product_model.update_fun(data_batch,\n",
      "                                codelens_batch,\n",
      "                                 sequence_lengths_batch,\n",
      "                                 prices_batch)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for data_batch, sequence_lengths_batch, codelens_batch, prices_batch in zip(data, sequence_lengths, codelens, prices):\n",
      "        print(product_model.update_fun(data_batch,\n",
      "                                      codelens_batch,\n",
      "                                 sequence_lengths_batch,\n",
      "                                 prices_batch))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "91.51292394974652\n",
        "188.14687757828656"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "263.16404846191404"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "895.6702992270974"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2345.0435384727925"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "5768.487396570094"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1165.3700647107294"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "5071.819581689274"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "17507.084276661593"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "112202.11320218808"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}